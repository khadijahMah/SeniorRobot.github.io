<!DOCTYPE html>
<html>
<head>
<link href='https://fonts.googleapis.com/css?family=Almendra' rel='stylesheet'>
<style>
.item1 { grid-area: research; }
.item2 { grid-area: content; }

.grid-container {
  display: grid;
  grid-template-areas:
    'research research research research research research'
    'content content content content content content'
    'content content content content content content'
    'content content content content content content'
    'content content content content content content';
  grid-gap: 20px;
  background-color:#fff;
  padding: 10px;
}
.grid-container > div {
  background-color: rgba(255, 255, 255, 0.8);
  text-align: center;
  background-color:#fff;
  padding: 20px 0;
  font-size: 30px;
}
ul {
    list-style-type: none;
    margin: 0;
    padding: 0;
    overflow: hidden;
    background-color: #f1f1f1;
}

li {
    float: left;
}

li a {
    display: block;
     color: #000;
    text-align: center;
    padding: 14px 16px;
    text-decoration: none;
}

li a:hover {
    background-color: #555;
}

p {
	font-family: Times New Roman;
    	font-size: 15px;
	margin: 15px;
	text-align: left;
}
body{
   background-color: #01183d;
}

</style>
</head>
<body>

<div class="content" style="width:80%;margin-top:30px;margin-left:auto;margin-right:auto;">
<ul>
  <li><a href="index.html">Home</a></li>
  <li><a href="research.html">Research</a></li>
  <li><a href="faq.html">FAQ</a></li>
</ul>

<div class="grid-container">
  <div class="item1" style="background-color:#cbd9ef;font-family: 'Almendra';"><h1>Research Background<h1></div>
  <div class="item2">
	<h5>Project Description</h5>
	<p>This project is designed as a part of a larger ongoing research project at Kennesaw State University called “Internet-of-Things based Smart Classroom Environment” 
	   undertaken by the Wireless Mobile Computing research group of the Department of Computer Science.
	   The purpose of this project is to increase the use of IoT Technologies by educators.
	   This project is therefore designed to implement an initial Raspberry Pi 3 to control a Raspberry Pi 3 Robotic Car (‘robot’) through means of a cloud server. 
	   More specifically, the initial Raspberry Pi 3 will be trained to recognize a set of pre-defined gestures through machine learning.
	   These gestures will be stored on a cloud server where they will be associated with particular action commands.  The robot will be subscribed to the cloud server in order to obtain these action commands. 
	   The robot will then execute scripts to react to these commands. Speech commands will also be gathered using a microphone connected to the initial Raspberry Pi 3. 
	   These commands will then be evaluated using natural language processing (NLP).  
	   Just as the machine learning results from the gesture data will be associated with an action the robot will ultimately take, the NLP results will similarly be associated with actions the robot will take.
	   Thus, the robot will be able to react to both a set of predefined gestures and a set of predefined voice commands.</p>
	<h5>Implementation Details</h5>
	<p>This project is an implementation of a Proof-of-Concept gesture and voice recognition system using a Raspberry Pi 3, cloud server and Raspberry Pi 3 Robotic car robot. 
		The system will contain an accelerometer,gyroscope and microscope that will feed data to the Raspberry Pi 3. 
		The accelerometer and gyroscope will provide sensor data to the Raspberry Pi and be processed through Machine Learning to accurately classify pre-defined gestures. 
		Similarly, the voice recognition portion of the system will use the  microphone to  recognize pre-defined voice commands. 
		These gestures and voice commands will be stored on a cloud server where they will be associated with particular action commands.  
		The robot will be subscribed to the cloud server in order to obtain these action commands from either gesture or voice input and execute a script to act accordingly.</p>
	<h5>Results</h5>
	<p>Text Here</p>
  </div>
</div>
</div>
</body>
</html>
